<h2 id="the-not-so-easy-task-of-analysing-reaction-times">The (not so) easy task of analysing reaction times.</h2>

<p><strong>This is the non-interactive Version of the analysis!</strong>
You can find the interactive notebook
<a href="/files/Reaction-Time-Ex-Gauss-I.html">here</a>, <strong>caution</strong> it’s about 7MB
in size, so not your average website!</p>

<p>All code can be found in rmarkdown documents on Github
<a href="https://github.com/SRSteinkamp/ReactionTimeWrangling/exgauss/">https://github.com/SRSteinkamp/ReactionTimeWrangling/exgauss</a></p>

<p>Analyzing reaction times has a long history in psychology and
(cognitive) neuroscience. Most people who studied Psychology in
university have conducted a classical psychological experiments. For
example investigating the <a href="https://en.wikipedia.org/wiki/Stroop_effect">Stroop
task</a>. You might have
encountered the stimuli, with the typical task to spell out loud as fast
as possible written color names:</p>

<ul>
  <li>$\color{red}{\text{RED}}$</li>
  <li>$\color{yellow}{\text{BLUE}}$</li>
  <li>$\color{blue}{\text{YELLOW}}$</li>
  <li>$\color{green}{\text{GREEN}}$</li>
</ul>

<p>After running such a task, with many more word-color pairs and different
participants, a typical question in undergrad might be: Are participants
significantly faster while reading matching color words
($\color{green}{\text{GREEN}}$) than reading non-matching color words
($\color{blue}{\text{GREEN}}$)? A straightforward answer would be to
to average the reaction times in the non-matching and matching
conditions for each participant and then compare the two conditions
using for example a <a href="https://en.wikipedia.org/wiki/Student%27s_t-test#Paired_samples">paired
t-test</a>.
Yes, if <em>p</em> &lt; 0.05 and no, if <em>p</em> &gt; 0.05.</p>

<p>Results are in and everything is fine? If you start wondering, whether
this is the <em>correct</em> way of analysis, you might find more and more and
<strong>is more</strong>. Different discussions about:</p>

<ul>
  <li>Should conditions across participants be averaged using the mean or
  the median?</li>
  <li>Should data be averaged at all?</li>
  <li>How to define outliers?</li>
  <li>…</li>
  <li>Could a drift-diffusion model provide the key insights?</li>
  <li>…</li>
  <li>Is null hypothesis significance testing meaningful?</li>
</ul>

<p>All of these questions are not really in my main field of expertise (no
worries I won’t deal with the last one ;) , but I found reading about
reaction time analyses weirdly entertaining and very interesting, and I
wanted to start with blogging. So here is the first one of a couple of
experiments I am planning to do. There is no particular order but all
are based on some questions that arose while looking at different
papers.</p>

<p>So maybe there is something useful here for you, or not. Or you disagree
or have comments, suggestions, etc. please get in touch!</p>

<p>Here is the first part:</p>

<h2 id="part-1---how-many-trials-do-i-need-to-fit-an-ex-gauss">Part 1 - How many trials do I need to fit an Ex-Gauss?</h2>

<p>Data below is generated sampling 100000 observations from two
Ex-Gaussian distributions with <em>μ</em> = 300, <em>σ</em> = 20, <em>τ</em> = 300 (red) and
<em>μ</em> = 500, <em>σ</em> = 50, <em>τ</em> = 100. Note, that both distributions have the
same mean of 600 (the black dashed line). To the left the two components
of the Ex-Gaussian are presented - the Gaussian and the Exponential
distributions. Here again the dashed-lines describe the mean of the
corresponding distributions.
<img src="/images/unnamed-chunk-2-1.png" alt="" /></p>

<p>The <a href="https://en.wikipedia.org/wiki/Exponentially_modified_Gaussian_distribution"><strong>Ex</strong>(ponential) <strong>Gauss</strong>(ian)
distribution</a>,
is the sum of a Gaussian distribution parametrized by <em>μ</em>, and <em>σ</em>,
which define the “body” of the distribution, with an Exponential
function (<em>τ</em>) describing the skew to the right. The normally
distributed body, with a long tail, has been found to closely match the
distribution of reaction time data found in many experiments (Palmer et
al. 2011). While the fit to experimental data seems to be ideal, the
parameters itself do not seem to be related to any specific cognitive
constructs. At least, the discussion is still ongoing (Spieler, Balota,
and Faust 2000). The strength of fitting distributions to reaction times
is seen in the ability to provide a finer description than for example a
summary of a certain condition using the mean or the median. Different
combinations of the Ex-Gauss parameters <em>μ</em> and <em>τ</em>, for example can
lead to the same mean. So comparing two conditions for example might
provide the same summary statistics, but the distributions might have a
very different spread and skew.</p>

<p>If you are interested in checking out more distributions (and more about
model fitting, etc.) visit this great page:
<a href="https://lindeloev.github.io/shiny-rt/">https://lindeloev.github.io/shiny-rt/</a></p>

<p>This is just a quick introduction into why fitting a distribution might
provide a better picture of reaction times, but how many trials are
necessary per condition?</p>

<h2 id="methods">Methods</h2>

<p>To simulate data I used the 12 Ex-Gauss distributions used by Miller
(1988), and many others. My assumption is, that a researcher wants to
fit an Ex-Gauss function for each condition and each participant in an
experiment. Note that, there are ways to estimate distributions across
multiple participants, which seem to be stable, even for small numbers
of trials(Ratcliff 1979), which I am not (yet?) going into. One estimate
is that around 100 trials might be needed to get reliable results
(Ratcliff 1979).</p>

<p>Here I want to investigate how many trials are needed, and whether there
are general biases in the estimation. For most of the analysis I am
using the <code class="language-plaintext highlighter-rouge">retimes</code> package. Data is simulated using <code class="language-plaintext highlighter-rouge">rexgauss</code> and for
model fitting using both the method of moments (<code class="language-plaintext highlighter-rouge">mexgauss</code>) and maximum
likelihood estimation (MLE) <code class="language-plaintext highlighter-rouge">timefit</code> are used. According to the
documentation <code class="language-plaintext highlighter-rouge">timefit</code> gets its starting parameters using the method of
moments.</p>

<p>I am simulating data from the 12 distributions starting with 10 (maybe a
rare-condition, like an oddball), up to 500 trials (a Psychophysicist’s
dream (Palmer et al. 2011)). For each of the twelve distributions I
sampled different numbers of trials (10, 20, 35, 50, 100, 200, 350, 500)
and then estimated the three parameters <em>μ</em>, <em>σ</em>, <em>τ</em> using the method
of moments and MLE. This processes was repeated 10000 times.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right">Distribution</th>
      <th style="text-align: right">Mu</th>
      <th style="text-align: right">Sigma</th>
      <th style="text-align: right">Tau</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: right">300</td>
      <td style="text-align: right">20</td>
      <td style="text-align: right">300</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: right">300</td>
      <td style="text-align: right">50</td>
      <td style="text-align: right">300</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: right">350</td>
      <td style="text-align: right">20</td>
      <td style="text-align: right">250</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: right">350</td>
      <td style="text-align: right">50</td>
      <td style="text-align: right">250</td>
    </tr>
    <tr>
      <td style="text-align: right">5</td>
      <td style="text-align: right">400</td>
      <td style="text-align: right">20</td>
      <td style="text-align: right">200</td>
    </tr>
    <tr>
      <td style="text-align: right">6</td>
      <td style="text-align: right">400</td>
      <td style="text-align: right">50</td>
      <td style="text-align: right">200</td>
    </tr>
    <tr>
      <td style="text-align: right">7</td>
      <td style="text-align: right">450</td>
      <td style="text-align: right">20</td>
      <td style="text-align: right">150</td>
    </tr>
    <tr>
      <td style="text-align: right">8</td>
      <td style="text-align: right">450</td>
      <td style="text-align: right">50</td>
      <td style="text-align: right">150</td>
    </tr>
    <tr>
      <td style="text-align: right">9</td>
      <td style="text-align: right">500</td>
      <td style="text-align: right">20</td>
      <td style="text-align: right">100</td>
    </tr>
    <tr>
      <td style="text-align: right">10</td>
      <td style="text-align: right">500</td>
      <td style="text-align: right">50</td>
      <td style="text-align: right">100</td>
    </tr>
    <tr>
      <td style="text-align: right">11</td>
      <td style="text-align: right">550</td>
      <td style="text-align: right">20</td>
      <td style="text-align: right">50</td>
    </tr>
    <tr>
      <td style="text-align: right">12</td>
      <td style="text-align: right">550</td>
      <td style="text-align: right">50</td>
      <td style="text-align: right">50</td>
    </tr>
  </tbody>
</table>

<h2 id="results">Results</h2>

<p>The histograms below describe our simulation results. Feel free to click
around (in the interactive version) and select different distributions
and methods. From our visual inspection we can see that using a small
number of trials can lead to quite some biases in the estimated
parameters. The spread of estimated parameters decreases the more
samples are considered. The data in the histograms is filtered to only
include parameter estimates greater than 0 and less than 750. The
histograms are calculated so that 40 bins for each sample are estimated
and only for sample sizes of 20, 100, 500). This might not be the best
way to display the data, but was done to keep the size of the HTML as
small as possible. Furthermore, some data cleaning had to be performed
as there are raw-events with very unlikely parameter estimates. In the
non-interactive version, there estimates for distribution 6 only,
however you can see <code class="language-plaintext highlighter-rouge">Moments</code> and <code class="language-plaintext highlighter-rouge">MLE</code> side by side.</p>

<h3 id="interactive-version-legend">Interactive Version Legend</h3>

<p>I couldn’t figure out how to put meaningful legends on the interactive
version: * red estimates for <em>μ</em>, solid bars distribution <em>μ</em> * blue
estimates for <em>τ</em>, dotted bars distribution <em>τ</em> * green estimates for
<em>σ</em>, dashed bars distribution <em>σ</em>
<img src="/images/unnamed-chunk-6-1.png" alt="" />
To get an estimate of how well (or bad) the modeling performed, I
calculated the <strong>mean</strong> error to investigate general trends, its
standard-deviation (<strong>SD</strong>), and the mean absolute error for error
estimation (<strong>MAE</strong>).</p>

<p>There is unfortunately, too much data to have good look at, so here is a
<code class="language-plaintext highlighter-rouge">datatable</code> to play around with and investigate some of the summary
values (in the interactive version only). Data can be created using the
<code class="language-plaintext highlighter-rouge">.Rmd</code> files in the
<a href="https://github.com/SRSteinkamp/ReactionTimeWrangling/exgauss/">Repro</a></p>

<h2 id="analysis">Analysis</h2>

<p>Plotting the summaries for the estimations and pooling over
distributions, we can draw first (maybe obvious) conclusions:</p>

<ul>
  <li>larger sample sizes, lead to less error</li>
  <li>maximum likelihood estimation performs generally better, than the
  method of moments.</li>
</ul>

<p>Interestingly, regardless of estimation procedure, the <em>σ</em> and <em>μ</em>
parameters seem to be overestimated, whereas <em>τ</em> is underestimated.</p>

<p><img src="/images/unnamed-chunk-9-1.png" alt="" /></p>

<h3 id="statistical-summary">Statistical Summary</h3>

<h4 id="how-strong-are-the-observed-biases">How strong are the observed biases?</h4>

<p><img src="/images/tm0.png" alt="" />
As we have already seen in the figure, we confirm that <em>μ</em> is generally
overestimated while, <em>τ</em> is underestimated. This makes sense given the
distribution of the data: The majority of data will be sampled from the
Gaussian part of the distribution, so extreme-values are relatively
rare. It is therefore much harder to correctly estimate the skew (<em>τ</em>).
As the mean of the Ex-Gaussian is given by <em>μ</em> + <em>τ</em>, a underestimation
of <em>τ</em> automatically leads to a larger estimate of <em>μ</em>.</p>

<p>Also, the method of moments seems to be more prone to biases, especially
leading to an overestimation of <em>σ</em>.</p>

<h4 id="what-can-we-learn-about-the-error">What can we learn about the error?</h4>

<p><img src="/images/tm123.png" alt="" /></p>

<p>All factors which were included in the model appear to have some meaning
(are significant). As we have seen in the other analysis, the method of
moments has a higher base MAE rate than the maximum likelihood
estimation. Furthermore, we can see that <em>μ</em> and <em>τ</em> are easier
identifiable the farther they are apart, especially when the method of
moments is used. This is expressed by the regressor diff_mt = <em>μ</em> − <em>τ</em>
(based on the original distributions). And again: larger sample sizes
are the key factor to reduce the error!</p>

<h2 id="conclusion">Conclusion</h2>

<p>If you want to get a good estimate of the reaction time distribution:
<strong>collect enough data!</strong></p>

<p>To provide a bit more nuance, you can get away with small sample sizes,
if you are lucky. For example if the reaction time distribution isn’t
very skewed. But keep in mind, that you can expect a higher error in the
estimation of the true parameters (especially using the method of
moments), when <em>τ</em> and <em>μ</em> are close to each other. Looking at the
histograms, we also see that there is a lot of variance in the
estimation of <em>σ</em>. So further analyzing <em>σ</em>, for example in a group
analysis, should be done very carefully. Last but not least, sample
sizes should be equal when comparing <em>μ</em> and <em>τ</em> across different
conditions! Even if parameters are drawn from the same Ex-Gauss
distribution, it is very likely that the condition with less trials will
have a higher estimate of these parameters. We can do a small simulation
of this using our simulated data.</p>

<h3 id="type-1-error-due-to-imbalanced-sample-sizes">Type 1 error due to imbalanced sample sizes</h3>

<p>For simplicity I decided to only use samples from distribution 6 (with
<em>μ</em> = 400, <em>τ</em> = 200, and <em>σ</em> = 50), estimated by MLE. I am drawing 30
random sets of estimated parameters for different combinations of sample
sizes. The number 30 is quite arbitrary but is supposed to reflect a
typical number of participants in an reaction time experiment. The
parameters of the different distributions are then submitted to a paired
two-sided t-test and the number of significant results (<em>p</em> &lt; 0.05) are
reported. In theory, as data is drawn from the same distribution, we
should expect around 5% false positive results.</p>

<p>Histogram of the simulation results. We can see that the first two pairs
have many false positives (<em>p</em> &lt; 0.05, left of the black line). The
later pairings on the other hand seem to have a rather uniform
distribution of p-values (as we would expect). The pairings (e.g., 20 :
50) show on how many trials the parameters in condition 1 (20) and in
condition 2 (50) were estimated. The paired t-tests were then calculated
as condition 1 &gt; condition 2.
<img src="/images/unnamed-chunk-14-1.png" alt="" /></p>

<p>For completeness sake I also calculated the average t-value for each of
the pairing, next to the proportion of false positive results.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Pairing</th>
      <th style="text-align: right">Mu_p</th>
      <th style="text-align: right">Mu_t</th>
      <th style="text-align: right">Tau_p</th>
      <th style="text-align: right">Tau_t</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">1 - 20 : 50</td>
      <td style="text-align: right">0.248</td>
      <td style="text-align: right">1.406</td>
      <td style="text-align: right">0.166</td>
      <td style="text-align: right">-1.065</td>
    </tr>
    <tr>
      <td style="text-align: left">2 - 20 : 200</td>
      <td style="text-align: right">0.378</td>
      <td style="text-align: right">1.762</td>
      <td style="text-align: right">0.256</td>
      <td style="text-align: right">-1.407</td>
    </tr>
    <tr>
      <td style="text-align: left">3 - 50 : 100</td>
      <td style="text-align: right">0.053</td>
      <td style="text-align: right">0.289</td>
      <td style="text-align: right">0.057</td>
      <td style="text-align: right">-0.293</td>
    </tr>
    <tr>
      <td style="text-align: left">4 - 50 : 200</td>
      <td style="text-align: right">0.060</td>
      <td style="text-align: right">0.434</td>
      <td style="text-align: right">0.068</td>
      <td style="text-align: right">-0.408</td>
    </tr>
    <tr>
      <td style="text-align: left">5 - 100 : 200</td>
      <td style="text-align: right">0.049</td>
      <td style="text-align: right">0.142</td>
      <td style="text-align: right">0.056</td>
      <td style="text-align: right">-0.092</td>
    </tr>
    <tr>
      <td style="text-align: left">6 - 200 : 200</td>
      <td style="text-align: right">0.050</td>
      <td style="text-align: right">-0.009</td>
      <td style="text-align: right">0.051</td>
      <td style="text-align: right">0.005</td>
    </tr>
  </tbody>
</table>

<p>As assumed, we have a inflation of false-positive t-tests when comparing
estimates of Ex-Gauss parameters from the same distribution (but
estimated using different sample-sizes). The larger the imbalance, the
larger the false positive rate!</p>

<h3 id="conclusions-not-related-to-analysis">Conclusions not related to analysis</h3>

<p>This is the first larger project I conducted in R(markdown). I really
don’t like the basic R syntax in many regards, but using <code class="language-plaintext highlighter-rouge">dplyr</code> and the
rest of the <code class="language-plaintext highlighter-rouge">tidyverse</code> is great :) <code class="language-plaintext highlighter-rouge">%&gt;%</code> it all the way! Building
interactive figures with <code class="language-plaintext highlighter-rouge">ggplot2</code> + <code class="language-plaintext highlighter-rouge">plotly</code> + <code class="language-plaintext highlighter-rouge">crosstalk</code> is also
quite amazing. But as I did not want to create a shiny app, figuring out
how to deal with exploding sizes of .html files took me quite some time.</p>

<h2 id="references">References</h2>

<p>Miller, Jeff. 1988. “A Warning About Median Reaction Time.” <em>Journal of
Experimental Psychology: Human Perception and Performance</em> 14 (3):
539–43. <a href="https://doi.org/10.1037/0096-1523.14.3.539">https://doi.org/10.1037/0096-1523.14.3.539</a>.</p>

<p>Palmer, Evan M., Todd S. Horowitz, Antonio Torralba, and Jeremy M.
Wolfe. 2011. “What Are the Shapes of Response Time Distributions in
Visual Search?” <em>Journal of Experimental Psychology: Human Perception
and Performance</em> 37 (1): 58–71. <a href="https://doi.org/10.1037/a0020747">https://doi.org/10.1037/a0020747</a>.</p>

<p>Ratcliff, Roger. 1979. “Group Reaction Time Distributions and an
Analysis of Distribution Statistics.” <em>Psychological Bulletin</em> 86 (3):
446–61. <a href="https://doi.org/10.1037/0033-2909.86.3.446">https://doi.org/10.1037/0033-2909.86.3.446</a>.</p>

<p>Spieler, Daniel H., David A. Balota, and Mark E. Faust. 2000. “Levels of
Selective Attention Revealed Through Analyses of Response Time
Distributions.” <em>Journal of Experimental Psychology: Human Perception
and Performance</em> 26 (2): 506–26.
<a href="https://doi.org/10.1037/0096-1523.26.2.506">https://doi.org/10.1037/0096-1523.26.2.506</a>.</p>
